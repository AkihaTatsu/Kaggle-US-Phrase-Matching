{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这些是你没有import的包\n",
    "#我的函数为FrameToSet、FrameToSet_test、train_the_deberta、test_the_deberta\n",
    "import gc\n",
    "import pyarrow as pa\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "import datasets\n",
    "import transformers\n",
    "#下面这3段与你一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, LoggingHandler, losses, models, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "from sentence_transformers.readers import InputExample\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import math\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for dirname, _, filenames in os.walk('./kaggle/input/us-patent-phrase-to-phrase-matching'):\n",
    "    for filename in filenames:\n",
    "        if filename == 'train.csv':\n",
    "            raw_data = pd.read_csv(os.path.join(dirname, filename))\n",
    "        elif filename == 'test.csv':\n",
    "            test_data = pd.read_csv(os.path.join(dirname, filename))\n",
    "        elif filename == 'sample_submission.csv':\n",
    "            sample_submission = pd.read_csv(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_eval(data, train_per=0.8, train_num=None):\n",
    "    if train_num is None:\n",
    "        train_num = int(len(data) * train_per)\n",
    "        \n",
    "    raw_data_index = list(range(len(data)))\n",
    "    random.shuffle(raw_data_index)\n",
    "    train_data = raw_data.loc[raw_data_index[:train_num]]\n",
    "    train_data = train_data.sort_index(ascending=True)\n",
    "    eval_data = raw_data.loc[raw_data_index[train_num:]]\n",
    "    eval_data = eval_data.sort_index(ascending=True)\n",
    "    return train_data, eval_data\n",
    "\n",
    "train_data, eval_data = split_train_eval(raw_data, train_num=len(raw_data) - 37 * 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameToSet(data):#将原dataframe转化为模型需要的dataframe\n",
    "    output_data = pd.DataFrame(columns=['sentence1', 'sentence2', 'context1', 'context2', 'label', 'idx'])\n",
    "    output_data['sentence1'] = list(data['anchor'])\n",
    "    output_data['sentence2'] = list(data['target'])\n",
    "    output_data['label'] = list(data['score'])\n",
    "    output_data['idx'] = list(np.arange(0,len(output_data['label'])))\n",
    "    contexts = []\n",
    "    for x in list(data['context']):\n",
    "        contexts.append([ord(x[0])-65,10*int(x[1])+int(x[2])])\n",
    "    output_data['context1'] = list(np.array(contexts)[:,0])\n",
    "    output_data['context2'] = list(np.array(contexts)[:,1])\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrameToSet_test(data):#与上函数的不同在于考虑测试集没有score，填充全0列\n",
    "    output_data = pd.DataFrame(columns=['sentence1', 'sentence2', 'context1', 'context2', 'label', 'idx'])\n",
    "    output_data['sentence1'] = list(data['anchor'])\n",
    "    output_data['sentence2'] = list(data['target'])\n",
    "    output_data['label'] = list([0.0]*len(output_data['sentence2']))\n",
    "    output_data['idx'] = list(np.arange(0,len(output_data['label'])))\n",
    "    contexts = []\n",
    "    for x in list(data['context']):\n",
    "        contexts.append([ord(x[0])-65,10*int(x[1])+int(x[2])])\n",
    "    output_data['context1'] = list(np.array(contexts)[:,0])\n",
    "    output_data['context2'] = list(np.array(contexts)[:,1])\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_the_deberta(train_data, eval_data, batch_size = 8,\n",
    "                      num_epoch = 3.0, model_checkpoint = \"microsoft/deberta-v3-small\",\n",
    "                      learning_rate = 5e-5, weight_decay = 0.01):\n",
    "    #DeBERTa模型\n",
    "    #train_data、eval_data需要最初的dataframe类型\n",
    "    #batch_size 这个不解释了，int型\n",
    "    #num_epoch 要求为float类型（没错，它默认是3.0）\n",
    "    #weight_decay 权值衰减,learning_rate 学习率,\n",
    "    #这些都是args = TrainingArguments()中的参数，想要调一些细节还可以help(TrainingArguments)查看更多参数\n",
    "    #返回值为模型(model)\n",
    "    \n",
    "    thetrain = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(FrameToSet(train_data)))\n",
    "    theeval = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(FrameToSet(eval_data)))\n",
    "    thedict = {\"train\":thetrain,\"validation\":theeval}\n",
    "    dataset = datasets.dataset_dict.DatasetDict(thedict)\n",
    "    #如果提交代码，运行下面这段(2/3)\n",
    "   \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    task = \"stsb\"\n",
    "    #List of glue keys\n",
    "    task_to_keys = {\n",
    "        \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    }\n",
    "    \n",
    "    #Collect sentence keys and labels\n",
    "    sentence1_key, sentence2_key = task_to_keys[task]\n",
    "    \n",
    "    # Number of logits to output\n",
    "    num_labels = 1\n",
    "    \n",
    "    ###  Tokenizing Section  ####\n",
    "    \n",
    "    # Create tokenizer for respective model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True, truncation=True, model_max_length=512)\n",
    "    \n",
    "    def tokenizer_func(examples):\n",
    "        if sentence2_key is None:\n",
    "            return tokenizer(examples[sentence1_key], truncation=True,)\n",
    "        return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True,)\n",
    "    \n",
    "    # tokenize sentence(s)\n",
    "    encoded_dataset = dataset.map(tokenizer_func, batched=True)\n",
    "    \n",
    "    ###  Model Section  ####\n",
    "    \n",
    "    # Create model and attach ForSequenceClassification head\n",
    "    model_deberta = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    #模型定义在上面这行\n",
    "    # Type of metric for given task\n",
    "    metric_name = \"pearson\"\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        f\"{model_checkpoint}-finetuned-Testing-{task}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=weight_decay,\n",
    "        metric_for_best_model=metric_name,\n",
    "        eval_accumulation_steps=5,\n",
    "        learning_rate=learning_rate,\n",
    "        num_train_epochs=num_epoch\n",
    "    )\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.squeeze(predictions)\n",
    "        labels = np.squeeze(labels)\n",
    "        if len(labels) <= 1:\n",
    "            return {\"peason\":1.0}\n",
    "        #长度低于2，pearsonr会报错\n",
    "        pea = pearsonr(predictions, labels)[0]\n",
    "        return {\"peason\":pea}\n",
    "    \n",
    "    validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\n",
    "    trainer = Trainer(\n",
    "        model_deberta,\n",
    "        args,\n",
    "        train_dataset=encoded_dataset[\"train\"],\n",
    "        eval_dataset=encoded_dataset[validation_key],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model()\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return model_deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_the_deberta(test_data, model_deberta, batch_size = 8,\n",
    "                      num_epoch = 3.0, model_checkpoint = \"microsoft/deberta-v3-small\",weight_decay = 0.01):\n",
    "    #test_data需要最初的dataframe类型\n",
    "    #model_checkpoint与训练时一致\n",
    "    #batch_size、num_epoch、weiight_decay不用管，预测不会用到的参数\n",
    "    #返回值为预测值，类型为np.array，维度为1\n",
    "\n",
    "    thetest = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(FrameToSet_test(thetest_)))\n",
    "    thedict = {\"test\":thetest}\n",
    "    dataset = datasets.dataset_dict.DatasetDict(thedict)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    task = \"stsb\"\n",
    "    #List of glue keys\n",
    "    task_to_keys = {\n",
    "        \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    }\n",
    "    #Collect sentence keys and labels\n",
    "    sentence1_key, sentence2_key = task_to_keys[task]\n",
    "    \n",
    "    # Number of logits to output\n",
    "    num_labels = 1\n",
    "    \n",
    "    ###  Tokenizing Section  ####\n",
    "    \n",
    "    #Load model    \n",
    "    # Create tokenizer for respective model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True, truncation=True, model_max_length=512)\n",
    "    \n",
    "    def tokenizer_func(examples):\n",
    "        if sentence2_key is None:\n",
    "            return tokenizer(examples[sentence1_key], truncation=True,)\n",
    "        return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True,)\n",
    "    \n",
    "    # tokenize sentence(s)\n",
    "    encoded_dataset = dataset.map(tokenizer_func, batched=True)\n",
    "    \n",
    "    ###  Model Section  ####\n",
    "    metric_name = \"pearson\"\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        f\"{model_checkpoint}-finetuned-Testing-{task}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=0.01,\n",
    "        metric_for_best_model=metric_name,\n",
    "        eval_accumulation_steps=5,\n",
    "        num_train_epochs=num_epoch\n",
    "    )\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.squeeze(predictions)\n",
    "        labels = np.squeeze(labels)\n",
    "        if len(labels) <= 1:\n",
    "            return {\"peason\":1.0}\n",
    "        #长度低于2，pearsonr会报错\n",
    "        pea = pearsonr(predictions, labels)[0]\n",
    "        return {\"peason\":pea}\n",
    "    \n",
    "    validation_key = \"validation_mismatched\" if task == \"mnli-mm\" else \"validation_matched\" if task == \"mnli\" else \"validation\"\n",
    "    trainer = Trainer(\n",
    "        model_deberta,\n",
    "        args,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    ### Predictions  ###\n",
    "    \n",
    "    prediction_one = trainer.predict(encoded_dataset[\"test\"])\n",
    "    #del trainer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return np.squeeze(prediction_one.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthe_train, thetest_ = split_train_eval(raw_data)#全部样本\\nthetrain_, theeval_ = split_train_eval(the_train)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data1, kkkkk = split_train_eval(raw_data, train_per = 0.1)#小样本测试，只取百分之十数据\n",
    "the_train, thetest_ = split_train_eval(raw_data1)\n",
    "thetrain_, theeval_ = split_train_eval(the_train)\n",
    "'''\n",
    "the_train, thetest_ = split_train_eval(raw_data)#全部样本\n",
    "thetrain_, theeval_ = split_train_eval(the_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###设置###\n",
    "model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "#有条件用下面这行\n",
    "#需要下载\n",
    "#model_checkpoint = \"microsoft/deberta-v3-large\"\n",
    "#model_checkpoint = \"google/electra-large-discriminator\"\n",
    "#model_checkpoint = \"xlnet-large-cased\"\n",
    "batch_size = 8#有条件大一些\n",
    "num_epoch = 3.0#就是float型，默认为3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "D:\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb99a5ec0854855b9fbaf08868f5954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0306d0521b460281b9ed221629277a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-small were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The following columns in the training set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context2, idx, context1, sentence1, sentence2. If context2, idx, context1, sentence1, sentence2 are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "D:\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2333\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 876\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='876' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [876/876 03:03, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Peason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.720784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.030662</td>\n",
       "      <td>0.785953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.801874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context2, idx, context1, sentence1, sentence2. If context2, idx, context1, sentence1, sentence2 are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 584\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to microsoft/deberta-v3-small-finetuned-Testing-stsb\\checkpoint-500\n",
      "Configuration saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\checkpoint-500\\config.json\n",
      "Model weights saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\checkpoint-500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context2, idx, context1, sentence1, sentence2. If context2, idx, context1, sentence1, sentence2 are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 584\n",
      "  Batch size = 8\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context2, idx, context1, sentence1, sentence2. If context2, idx, context1, sentence1, sentence2 are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 584\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to microsoft/deberta-v3-small-finetuned-Testing-stsb\n",
      "Configuration saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\config.json\n",
      "Model weights saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\pytorch_model.bin\n",
      "tokenizer config file saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\tokenizer_config.json\n",
      "Special tokens file saved in microsoft/deberta-v3-small-finetuned-Testing-stsb\\special_tokens_map.json\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at C:\\Users\\Mottled-panpipe/.cache\\huggingface\\transformers\\8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/spm.model from cache at C:\\Users\\Mottled-panpipe/.cache\\huggingface\\transformers\\3ed0740946d0a60434dd6a0c940068899c0b48bb5caba7d60c1db454877c64a3.0abaeacf7287ee8ba758fec15ddfb4bb6c697bb1a8db272725f8aa633501787a\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/tokenizer_config.json from cache at C:\\Users\\Mottled-panpipe/.cache\\huggingface\\transformers\\b40830d1301d39fdc8c6a059787f7f46b8786c252b5475512aa5cf0a66020075.df5a7f41459442f66bec27ac9352bba694cde109855024b3ae61be2f5734ee9a\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at C:\\Users\\Mottled-panpipe/.cache\\huggingface\\transformers\\8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "Adding [MASK] to the vocabulary\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file https://huggingface.co/microsoft/deberta-v3-small/resolve/main/config.json from cache at C:\\Users\\Mottled-panpipe/.cache\\huggingface\\transformers\\8e0c12a7672d1d36f647c86e5fc3a911f189d8704e2bc94dde4a1ffe38f648fa.9df96bac06c2c492bc77ad040068f903c93beec14607428f25bf9081644ad0da\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.19.3\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "D:\\anaconda3\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d76f3c5f104bf8ac2f7fab05089702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set don't have a corresponding argument in `DebertaV2ForSequenceClassification.forward` and have been ignored: context2, idx, context1, sentence1, sentence2. If context2, idx, context1, sentence1, sentence2 are not expected by `DebertaV2ForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 730\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [92/92 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:3845: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8426112532787519"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#模型使用示例\n",
    "model = train_the_deberta(thetrain_, theeval_, batch_size = batch_size, num_epoch = num_epoch, model_checkpoint = model_checkpoint)\n",
    "thepredicts = test_the_deberta(thetest_, model, model_checkpoint = model_checkpoint)\n",
    "pearsonr(thepredicts, np.array(thetest_['score']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    thetrain = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(ftrain.loc[ftrain[\"context1\"]==i]))\\n    thetest = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(ftest.loc[ftest[\"context1\"]==i]))\\n    theeval = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(feval.loc[feval[\"context1\"]==i]))\\n    thedict = {\"train\":thetrain,\"validation\":theeval,\"test\":thetest}\\n    dataset = datasets.dataset_dict.DatasetDict(thedict)\\n    task = \"stsb\"\\n    #List of glue keys\\n    task_to_keys = {\\n        \"stsb\": (\"sentence1\", \"sentence2\"),\\n    }\\n    #Select task\\n    #task = \"rte\"  #cola, mrpc\\n    #batch_size = 8 #10 normally, 8 for qnli\\n    \\n    # Load dataset based on task variable\\n    #dataset = load_dataset(\"glue\", actual_task)\\n    \\n    #Collect sentence keys and labels\\n    sentence1_key, sentence2_key = task_to_keys[task]\\n    \\n    # Number of logits to output\\n    num_labels = 1\\n    \\n    ###  Tokenizing Section  ####\\n    # tokenize sentence(s)\\n    encoded_dataset = dataset.map(tokenizer_func, batched=True)\\n    \\n    \\n    #model_checkpoint = \"deberta-v3-small_baseline_cola/\"\\n    #model_checkpoint = \"deberta-v3-small_baseline_\"+actual_task+\"/\"\\n    \\n    ###  Model Section  ####\\n    \\n    # Create model and attach ForSequenceClassification head\\n    model_deberta = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\\n    ########################模型定义在上面这行\\n    \\n    # Type of metric for given task\\n    metric_name = \"pearson\"\\n    \\n    args = TrainingArguments(\\n        f\"{model_checkpoint}-finetuned-Testing-{task}\",\\n        evaluation_strategy = \"epoch\",\\n        per_device_train_batch_size=batch_size,\\n        per_device_eval_batch_size=batch_size,\\n        weight_decay=0.01,\\n        metric_for_best_model=metric_name,\\n        eval_accumulation_steps=5,\\n        num_train_epochs=num_epoch\\n    )\\n    \\n    def compute_metrics(eval_pred):\\n        predictions, labels = eval_pred\\n        predictions = predictions[:]#, 0]\\n        pea = pearsonr(predictions, labels)[0]\\n        return {\"peason\":pea}#metric.compute(predictions=predictions, references=labels)\\n    \\n    validation_key = \"validation\"\\n    trainer = Trainer(\\n        model_deberta,\\n        args,\\n        train_dataset=encoded_dataset[\"train\"],\\n        eval_dataset=encoded_dataset[validation_key],\\n        tokenizer=tokenizer,\\n        compute_metrics=compute_metrics\\n    )\\n    trainer.train()#训练过程\\n    model_deberta.save()\\n\\n    \\n    ### Collect Predictions  ###\\n    \\n    predicts = trainer.predict(encoded_dataset[\"test\"])\\n    pre.append(np.vstack((predicts.predictions, np.array(ftest.loc[ftest[\"context1\"]==i][\\'idx\\']))))\\n\\n    \\n    ## 清理gpu，不然容易炸\\n    del predicts\\n    del trainer\\n    del args\\n    del model_deberta\\n    del encoded_dataset\\n    del dataset\\n    del thedict\\n    del theeval\\n    del thetest\\n    del thetrain\\n    gc.collect()\\n    torch.cuda.empty_cache()\\n#将各模型结果按原顺序排好\\nspre = pre[0]\\nfor i in range(1,len(pre)):\\n    spre = np.concatenate((spre, pre[i]), axis=1)\\nspre = spre[:,spre[1].argsort()]\\n#sper[0]是最终的预测结果\\npearsonr(spre[0],np.array(ftest[\"label\"]))[0]\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#DeBERTa模型       按ABCD分类\n",
    "\n",
    "ftrain = FrameToSet(thetrain_)\n",
    "ftest = FrameToSet(thetest_)\n",
    "feval = FrameToSet(theeval_)\n",
    "#如果提交代码，运行下面这段(3/3)\n",
    "'''\n",
    "'''\n",
    "ftrain = FrameToSet(thetrain_)\n",
    "ftest = FrameToSet_test(thetest_)#这行不一样\n",
    "feval = FrameToSet(theeval_)\n",
    "\n",
    "\n",
    "pre = []\n",
    "\n",
    "metric = load_metric('glue', \"stsb\")#这行需要下载东西##########################################################################\n",
    "#Load model\n",
    "#model_checkpoint = \"microsoft/deberta-v3-small\"\n",
    "# Create tokenizer for respective model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True, truncation=True, model_max_length=512)\n",
    "    \n",
    "def tokenizer_func(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True,)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True,)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "'''\n",
    "#这里注意一下你分类的时候要处理下，训练集只有A~H，但测试集可能有别的\n",
    "#for i in range(9):\n",
    "#    if i == 8:#bigger context not in A~H\n",
    "#        all_id = ftest.loc[ftest[\"context1\"]>7]['idx']\n",
    "#        if len(all_id) > 0:\n",
    "#            p = []\n",
    "#            for idx in all_id:\n",
    "#                p.append(prediction_one.predictions[idx])\n",
    "#            pre.append(np.vstack((np.array(p), np.array(ftest.loc[ftest[\"context1\"]>7]['idx']))))\n",
    "#        break\n",
    "'''\n",
    "    thetrain = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(ftrain.loc[ftrain[\"context1\"]==i]))\n",
    "    thetest = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(ftest.loc[ftest[\"context1\"]==i]))\n",
    "    theeval = datasets.arrow_dataset.Dataset(pa.Table.from_pandas(feval.loc[feval[\"context1\"]==i]))\n",
    "    thedict = {\"train\":thetrain,\"validation\":theeval,\"test\":thetest}\n",
    "    dataset = datasets.dataset_dict.DatasetDict(thedict)\n",
    "    task = \"stsb\"\n",
    "    #List of glue keys\n",
    "    task_to_keys = {\n",
    "        \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    }\n",
    "    #Select task\n",
    "    #task = \"rte\"  #cola, mrpc\n",
    "    #batch_size = 8 #10 normally, 8 for qnli\n",
    "    \n",
    "    # Load dataset based on task variable\n",
    "    #dataset = load_dataset(\"glue\", actual_task)\n",
    "    \n",
    "    #Collect sentence keys and labels\n",
    "    sentence1_key, sentence2_key = task_to_keys[task]\n",
    "    \n",
    "    # Number of logits to output\n",
    "    num_labels = 1\n",
    "    \n",
    "    ###  Tokenizing Section  ####\n",
    "    # tokenize sentence(s)\n",
    "    encoded_dataset = dataset.map(tokenizer_func, batched=True)\n",
    "    \n",
    "    \n",
    "    #model_checkpoint = \"deberta-v3-small_baseline_cola/\"\n",
    "    #model_checkpoint = \"deberta-v3-small_baseline_\"+actual_task+\"/\"\n",
    "    \n",
    "    ###  Model Section  ####\n",
    "    \n",
    "    # Create model and attach ForSequenceClassification head\n",
    "    model_deberta = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "    ########################模型定义在上面这行\n",
    "    \n",
    "    # Type of metric for given task\n",
    "    metric_name = \"pearson\"\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        f\"{model_checkpoint}-finetuned-Testing-{task}\",\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        weight_decay=0.01,\n",
    "        metric_for_best_model=metric_name,\n",
    "        eval_accumulation_steps=5,\n",
    "        num_train_epochs=num_epoch\n",
    "    )\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = predictions[:]#, 0]\n",
    "        pea = pearsonr(predictions, labels)[0]\n",
    "        return {\"peason\":pea}#metric.compute(predictions=predictions, references=labels)\n",
    "    \n",
    "    validation_key = \"validation\"\n",
    "    trainer = Trainer(\n",
    "        model_deberta,\n",
    "        args,\n",
    "        train_dataset=encoded_dataset[\"train\"],\n",
    "        eval_dataset=encoded_dataset[validation_key],\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()#训练过程\n",
    "    model_deberta.save()\n",
    "\n",
    "    \n",
    "    ### Collect Predictions  ###\n",
    "    \n",
    "    predicts = trainer.predict(encoded_dataset[\"test\"])\n",
    "    pre.append(np.vstack((predicts.predictions, np.array(ftest.loc[ftest[\"context1\"]==i]['idx']))))\n",
    "\n",
    "    \n",
    "    ## 清理gpu，不然容易炸\n",
    "    del predicts\n",
    "    del trainer\n",
    "    del args\n",
    "    del model_deberta\n",
    "    del encoded_dataset\n",
    "    del dataset\n",
    "    del thedict\n",
    "    del theeval\n",
    "    del thetest\n",
    "    del thetrain\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "#将各模型结果按原顺序排好\n",
    "spre = pre[0]\n",
    "for i in range(1,len(pre)):\n",
    "    spre = np.concatenate((spre, pre[i]), axis=1)\n",
    "spre = spre[:,spre[1].argsort()]\n",
    "#sper[0]是最终的预测结果\n",
    "pearsonr(spre[0],np.array(ftest[\"label\"]))[0]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
